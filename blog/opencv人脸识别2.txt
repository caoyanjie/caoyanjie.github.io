import cv2
from matplotlib import pyplot as plt
import numpy as np
import time
import threading
import inspect
from collections import  deque
# 人脸识别
#import sys, os
#from cv2 import *
#from cv2.highgui import *
#from PIL import Image, ImageDraw
#from math import sqrt
##

def log(*vars):
    finfo = inspect.getframeinfo(inspect.currentframe().f_back)[3][0].strip()
    var_with_sep = finfo[finfo.find('(')+1 : finfo.rfind(')')]
    var_items = [item.strip() for item in var_with_sep.split(',')]
    index = 0
    for var in vars:
        print('%s:' % var_items[index], var)
        index += 1


class OpenCVExercise:
    def __init__(self):
        self.__img_path = 'D:/aaa.jpg'
        self.__img_ball = 'D:/ball.png'
        self.__img_digits = 'D:/digits.png'
        self.__video_path = 'F:/1.mp4'

    def __sub_thread(self, command, timeout):
        time.sleep(timeout)
        eval(command)

    # 加载图片，显示图片，保存图片
    def test1(self):
        # 加载图片
        img = cv2.imread(self.__img_path)

        # 显示图片
        cv2.imshow('wow', img)                                                                      # 窗口1

        cv2.imshow('wow1', img)                                                                     # 窗口2

        cv2.namedWindow('wow2', cv2.WINDOW_NORMAL)                                                  # 窗口3
        cv2.imshow('wow2', img)

        key = cv2.waitKey(2000)                                                                        # 等待键盘输入，参数时间单位为毫秒，参数0表示无限等待时间
        cv2.destroyAllWindows()                                                                     # 销毁所有窗口

        # 保存图片
        if ord('s') == key:
            cv2.imwrite('my_img.png', img)                                                          # 图片名必须要有后缀名

        # 使用 matplotlib 显示图片
        plt.imshow(img, cmap='gray', interpolation='bicubic')
        plt.xticks([]), plt.yticks([])                                                              # 隐藏坐标轴
        sub = threading.Thread(target=self.__sub_thread, args=('plt.close()', 2))
        sub.start()
        plt.show()

    # 从摄像头捕获视频或从文件读取视频
    def test2(self):
        reader = cv2.VideoCapture(0)                                                                # 从摄像头捕获视频
        #reader = cv2.VideoCapture('F:/1.mp4')                                                       # 从文件读取视频
        writer_fourcc = cv2.VideoWriter_fourcc(*'DIVX')                                             # 保存视频用
        #writer_fourcc = cv2.cv.FOURCC(*'XVID')
        writer = cv2.VideoWriter('output.avi', writer_fourcc, 20.0, (640, 480))                     # 保存视频用
        while reader.isOpened():
            result, frame = reader.read()                                                           # 获取每一帧的宽 cap.get(3)  #设置宽 ret = cap.set(3, 320)# 获取每一帧的高 cap.get(4)  # 设置高 ret = cap.set(4, 240)
            if result:
                # frame = cv2.flip(frame, 0)                                                          # 颠倒图片
                # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)                                     # 灰度图
                cv2.imshow('frame', frame)                                                          # 显示每一帧图片
                writer.write(frame)                                                                 # 保存视频
                if cv2.waitKey(25) == ord('q'):                                                     # 没帧间隔25毫秒，按下q键退出
                    break
        reader.release()
        writer.release()
        cv2.destroyAllWindows()

    # 绘图，画各种线，矩形，圆，多边形，文字
    def test3(self):
        img = np.zeros((512, 512, 3), np.uint8)

        cv2.line(img, (0, 0), (511, 511), (255, 0, 0), 5)                                           # 画线，参数为：起点坐标，终点坐标，线的颜色，线的宽度(-1为填充封闭的图形) cv2.polylines()
        cv2.rectangle(img, (384, 0), (510, 128), (0, 255, 0), 3)                                    # 画矩形，参数为：左上角坐标，右下角坐标，线的颜色，线的宽度
        cv2.circle(img, (447, 63), 63, (0, 0, 255), -1)                                             # 画圆，参数为：圆心坐标，半径长度，颜色，-1为填充封闭的图形
        cv2.ellipse(img, (256, 256), (100, 50), 0, 0, 180, 255, -1)                                 # 画椭圆，参数为：中心点坐标，长轴和短轴长度，椭圆沿逆时针方向旋转的角度，椭圆弧沿顺时针方向起始的角度和结束的角度(如果是0和360，就是整个椭圆)
        pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32).reshape(-1, 1, 2)                # 画多边形，
        cv2.putText(img, 'OpenCV', (10, 500), cv2.FONT_HERSHEY_SIMPLEX,  4, (255, 255, 255), 2)     # 绘制文字

        cv2.imshow('line', img)
        cv2.waitKey(2000)                                                                           # 不能用time.sleep()，不然画面出不来
        cv2.destroyAllWindows()

    # 把鼠标当画笔
    def test4(self):
        def draw_circle(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDBLCLK:
                cv2.circle(img, (x, y), 100, (255, 0, 0), -1)
        img = np.zeros((512, 512, 3), np.uint8)
        cv2.namedWindow('image')
        cv2.setMouseCallback('image', draw_circle)
        while True:
            cv2.imshow('image', img)
            if cv2.waitKey(20) == ord('q'):
                break
        cv2.destroyAllWindows()

    # 把鼠标当画笔
    def test5(self):
        drawing = False
        mode = True
        ix, iy = -1, -1

        def draw_circle(event, x, y, flags, param):
            global ix, iy, drawing, mode
            if event == cv2.EVENT_LBUTTONDOWN:
                drawing = True
                ix, iy = x, y
            elif event == cv2.EVENT_MOUSEMOVE and flags == cv2.EVENT_FLAG_LBUTTON:
                if drawing:
                    if mode:
                        cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), -1)
                    else:
                        cv2.circle(img, (x, y), 3, (0, 0, 255), -1)
            elif event == cv2.EVENT_LBUTTONUP:
                drawing = False
        img = np.zeros((512, 512, 3), np.uint8)
        cv2.namedWindow('image')
        cv2.setMouseCallback('image', draw_circle)
        while True:
            cv2.imshow('image', img)
            key = cv2.waitKey(1)
            if key == ord('m'):
                mode = not mode
            elif key == ord('q'):
                break

    # 用滑动条做调色板
    def test6(self):
        img = np.zeros((300, 512, 3), np.uint8)
        cv2.namedWindow('image')
        cv2.createTrackbar('R', 'image', 0, 255, self.__nothing)
        cv2.createTrackbar('G', 'image', 0, 255, self.__nothing)
        cv2.createTrackbar('B', 'image', 0, 255, self.__nothing)
        switch = '0:OFF\n1:ON'
        cv2.createTrackbar(switch, 'image', 0, 1, self.__nothing)
        while True:
            cv2.imshow('image', img)
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            r = cv2.getTrackbarPos('R', 'image')
            g = cv2.getTrackbarPos('G', 'image')
            b = cv2.getTrackbarPos('B', 'image')
            s = cv2.getTrackbarPos(switch, 'image')
            if s == 0:
                img[:] = 0
            else:
                print(b, g, r)
                img[:] = [b, g, r]
        cv2.destroyAllWindows()

    # 获取并修改像素值
    def test7(self):
        img = cv2.imread(self.__img_path)
        px = img[100, 100]
        print(px)
        blue = img[100, 100, 0]
        print(blue)
        cv2.imshow('source', img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

        img[100, 100] = [255, 255, 255]
        print(img[100, 100])
        cv2.imshow('source', img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

        print(img.item(10, 10, 2))
        img.itemset((10, 10, 2), 100)
        print(img.item(10, 10, 2))

    # 获取图像属性
    def test8(self):
        img = cv2.imread(self.__img_path)
        print(img.shape)                        # 返回图像的 行数，列数，通道数
        print(img.size)                         # 返回图形的像素数目
        print(img.dtype)                        # 返回图像的数据类型

    # 图像的区域拷贝
    def test9(self):
        img = cv2.imread(self.__img_ball)
        ball = img[280:340, 330:390]
        img[273:333, 100:160] = ball
        cv2.imshow('two ball', img)
        cv2.waitKey(0)

    # 通道的拆分合并
    def test10(self):
        img = cv2.imread(self.__img_ball)
        b, g, r = cv2.split(img)                # 比较耗时
        img2 = cv2.merge((b, g, r))
        cv2.imshow('merge', img2)
        cv2.waitKey(0)
        img[:, :, 2] = 0
        cv2.imshow('merge', img)
        cv2.waitKey(0)

    # 为图像扩边(填充)
    def test11(self):
        pass

    # 追踪视频中的红色
    def test19(self):
        # 设定红色阈值，HSV空间
        redLower = np.array([170, 100, 100])
        redUpper = np.array([179, 255, 255])
        # 初始化追踪点的列表
        mybuffer = 16
        pts = deque(maxlen=mybuffer)
        counter = 0
        # 打开摄像头
        camera = cv2.VideoCapture(1)
        # 等待两秒
        time.sleep(3)
        # 遍历每一帧，检测红色瓶盖
        while True:
            # 读取帧
            (ret, frame) = camera.read()
            # 判断是否成功打开摄像头
            if not ret:
                print
                'No Camera'
                break
                # frame = imutils.resize(frame, width=600)
            # 转到HSV空间
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            # 根据阈值构建掩膜
            mask = cv2.inRange(hsv, redLower, redUpper)
            # 腐蚀操作
            mask = cv2.erode(mask, None, iterations=2)
            # 膨胀操作，其实先腐蚀再膨胀的效果是开运算，去除噪点
            mask = cv2.dilate(mask, None, iterations=2)
            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
            # 初始化瓶盖圆形轮廓质心
            center = None
            # 如果存在轮廓
            if len(cnts) > 0:
                # 找到面积最大的轮廓
                c = max(cnts, key=cv2.contourArea)
                # 确定面积最大的轮廓的外接圆
                ((x, y), radius) = cv2.minEnclosingCircle(c)
                # 计算轮廓的矩
                M = cv2.moments(c)
                # 计算质心
                center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
                # 只有当半径大于10时，才执行画图
                if radius > 10:
                    cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)
                    cv2.circle(frame, center, 5, (0, 0, 255), -1)
                    # 把质心添加到pts中，并且是添加到列表左侧
                    pts.appendleft(center)
            else:  # 如果图像中没有检测到瓶盖，则清空pts，图像上不显示轨迹。
                pts.clear()

            for i in range(1, len(pts)):
                if pts[i - 1] is None or pts[i] is None:
                    continue
                    # 计算所画小线段的粗细
                thickness = int(np.sqrt(mybuffer / float(i + 1)) * 2.5)
                # 画出小线段
                cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)
                # 判断移动方向
                if counter >= 10 and i == 1 and len(pts) >= 10:
                    dX = pts[-10][0] - pts[i][0]
                    dY = pts[-10][1] - pts[i][1]
                    (dirX, dirY) = ("", "")

                    if np.abs(dX) > 20:
                        dirX = "East" if np.sign(dX) == 1 else "West"

                    if np.abs(dY) > 20:
                        dirY = "North" if np.sign(dY) == 1 else "South"

                    if dirX != "" and dirY != "":
                        direction = "{}-{}".format(dirY, dirX)
                    else:
                        direction = dirX if dirX != "" else dirY

                    cv2.putText(frame, direction, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2,
                                (0, 255, 0), 3)
                    cv2.putText(frame, "dx: {}, dy: {}".format(dX, dY), (10, frame.shape[0] - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)

                cv2.imshow('Frame', frame)
                # 键盘检测，检测到esc键退出
                k = cv2.waitKey(1) & 0xFF
                counter += 1
                if k == 27:
                    break
                    # 摄像头释放
            camera.release()
            # 销毁所有窗口
            cv2.destroyAllWindows()

    # 转换颜色空间 物体跟踪
    def test20(self):
        cv2.namedWindow('video_window')
        lh, ls, lv = 0, 0, 0
        uh, us, uv = 179, 255, 255
        lower_hsv = np.array([lh, ls, lv])
        upper_hsv = np.array([uh, us, uv])
        isfirst = True

        def get_mouse_pos_color(event, x, y, flags, param):
            nonlocal lh, ls, lv, uh, us, uv, lower_hsv, upper_hsv, isfirst
            if event == cv2.EVENT_LBUTTONDOWN:
                hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                h, s, v = hsv1[y, x]
                h, s, v = int(h), int(s), int(v)
                if isfirst:
                    lh, ls, lv = h, s, v
                    uh, us, uv = h, s, v
                    isfirst = False
                else:
                    lh, ls, lv = min(lh, h), min(ls, s), min(lv, v)
                    uh, us, uv = max(uh, h), max(us, s), max(uv, v)

                lower_hsv = np.array([lh, ls, lv])
                upper_hsv = np.array([uh, us, uv])

        cv2.setMouseCallback('video_window', get_mouse_pos_color)

        cap = cv2.VideoCapture(1)
        while cap.isOpened():
            result, frame = cap.read()
            if not result:
                continue

            # 转换到 HSV
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

            # 设定蓝色的阈值
            upper_v = cv2.getTrackbarPos('upper_v', 'result_window')

            # 根据阈值构建掩码
            mask = cv2.inRange(hsv, lower_hsv, upper_hsv)

            # 对原图像和掩码进行位运算
            res = cv2.bitwise_and(frame, frame, mask=mask)

            # 显示图像
            cv2.imshow('video_window', frame)
            cv2.imshow('mask_window', mask)
            cv2.imshow('result_window', res)
            if cv2.waitKey(100) == ord('q'):
                break

        cv2.destroyAllWindows()

    # 检测图片某区域的hsv阈值
    def test21(self, file_full_path):
        cv2.namedWindow('src')
        #cv2.namedWindow('mask', cv2.WINDOW_NORMAL)
        #cv2.namedWindow('result', cv2.WINDOW_NORMAL)
        lh, ls, lv = 0, 0, 0
        uh, us, uv = 179, 255, 255
        lower_hsv = np.array([lh, ls, lv])
        upper_hsv = np.array([uh, us, uv])
        isfirst = True

        def get_mouse_pos_color(event, x, y, flags, param):
            nonlocal lh, ls, lv, uh, us, uv, lower_hsv, upper_hsv, isfirst
            if event == cv2.EVENT_LBUTTONDOWN:
                hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                h, s, v = hsv1[y, x]
                h, s, v = int(h), int(s), int(v)
                if isfirst:
                    lh, ls, lv = h, s, v
                    uh, us, uv = h, s, v
                    isfirst = False
                else:
                    lh, ls, lv = min(lh, h), min(ls, s), min(lv, v)
                    uh, us, uv = max(uh, h), max(us, s), max(uv, v)

                lower_hsv = np.array([lh, ls, lv])
                upper_hsv = np.array([uh, us, uv])

        cv2.setMouseCallback('video_window', get_mouse_pos_color)

        frame = cv2.imdecode(np.fromfile(file_full_path, dtype=np.uint8), 1)

        # 转换到 HSV
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

        # 设定蓝色的阈值
        while True:
            upper_v = cv2.getTrackbarPos('upper_v', 'result_window')

            # 根据阈值构建掩码
            mask = cv2.inRange(hsv, lower_hsv, upper_hsv)

            # 对原图像和掩码进行位运算
            res = cv2.bitwise_and(frame, frame, mask=mask)
            cv2.putText(res, f'H:{lh}-{uh}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255, 255, 255), 1)
            cv2.putText(res, f'S:{ls}-{us}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255, 255, 255), 1)
            cv2.putText(res, f'V:{lv}-{uv}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255, 255, 255), 1)

            # 显示图像
            cv2.imshow('src', frame)
            cv2.imshow('mask', mask)
            cv2.imshow('result', res)
            k = cv2.waitKey(5)
            if k == ord('q'):
                break
        cv2.destroyAllWindows()

    # Canny 边界检测
    def test50(self):
        img = cv2.imread(self.__img_ball, 0)
        edges1 = cv2.Canny(img, 100, 200)
        edges2 = cv2.Canny(img, 100, 300)
        cv2.imshow('Source', img)
        cv2.imshow('Canny1', edges1)
        cv2.imshow('Canny2', edges2)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

    def test100(self):
        img = cv2.imread(self.__img_ball)
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kernel = np.ones((5, 5), np.uint8)
        opening = cv2.morphologyEx(img_gray, cv2.MORPH_OPEN, kernel)
        th2 = cv2.adaptiveThreshold(opening, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 20)
        cv2.imshow('gray', img_gray)
        cv2.imshow('th2', th2)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

    def test98(self):
        img = cv2.imread(self.__img_ball)
        mask = np.zeros(img.shape[:2], np.uint8)
        bgdModel = np.zeros((1, 65), np.float64)
        fgdModel = np.zeros((1, 65), np.float64)
        rect = (50, 50, 450, 290)
        # 函数的返回值是更新的 mask, bgdModel, fgdModel
        cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)
        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
        img = img * mask2[:, :, np.newaxis]
        plt.imshow(img), plt.colorbar(), plt.show()
        newmask = cv2.imread('newmask.png', 0)
        # whereever it is marked white (sure foreground), change mask=1
        # whereever it is marked black (sure background), change mask=0
        mask[newmask == 0] = 0
        mask[newmask == 255] = 1
        mask, bgdModel, fgdModel = cv2.grabCut(img, mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)
        mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
        img = img * mask[:, :, np.newaxis]
        plt.imshow(img), plt.colorbar(), plt.show()

    def test101(self):
        cap = cv2.VideoCapture(self.__video_path)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        fgbg = cv2.createBackgroundSubtractorGMG()
        #fgbg = cv2.createBackgroundSubtractorKNN()
        fgbg = cv2.createBackgroundSubtractorMOG2()
        while True:
            ret, frame = cap.read()
            if ret:
                fgmask = fgbg.apply(frame)
                fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)
                cv2.imshow('frame', fgmask)
                k = cv2.waitKey(30) & 0xff
                if k == 27:
                    break
        cap.release()
        cv2.destroyAllWindows()

    # 检测运动物体
    def test102(self):
        cap = cv2.VideoCapture(0)
        fgbg = cv2.createBackgroundSubtractorMOG2()
        while True:
            ret, frame = cap.read()
            fgmask = fgbg.apply(frame)
            cv2.imshow('frame', fgmask)
            print(fgmask)
            key = cv2.waitKey(30)
            if key == 27:
                break
        cap.release()
        cv2.destroyAllWindows()

    # 检测运动物体
    def test103(self):
        cap = cv2.VideoCapture(0)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        fgbg = cv2.bgsegm.createBackgroundSubtractorGMG()
        while True:
            ret, frame = cap.read()
            fgmask = fgbg.apply(frame)
            fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)
            cv2.imshow('frame', fgmask)
            key = cv2.waitKey(30)
            if key == 27:
                break
        cap.release()
        cv2.destroyAllWindows()

    def test104(self):
        camera = cv2.VideoCapture(0)
        firstframe = None
        while True:
            ret, frame = camera.read()
            if not ret:
                break
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (21, 21), 0)
            if firstframe is None:
                firstframe = gray
                continue

            frameDelta = cv2.absdiff(firstframe, gray)
            thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]
            thresh = cv2.dilate(thresh, None, iterations=2)
            # cnts= cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)

            x, y, w, h = cv2.boundingRect(thresh)
            frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)
            cv2.imshow("frame", frame)
            cv2.imshow("Thresh", thresh)
            cv2.imshow("frame2", frameDelta)
            key = cv2.waitKey(1) & 0xFF

            if key == ord("q"):
                break

        camera.release()
        cv2.destroyAllWindows()

    # 可行的运动物体追踪
    def test105(self):
        tracker = cv2.TrackerMIL_create()
        video = cv2.VideoCapture(1)
        result, frame = video.read()
        bbox = (100, 100, 100, 100)
        ok = tracker.init(frame, bbox)
        while True:
            result, frame = video.read()
            ok, bbox = tracker.update(frame)
            if ok:
                p1 = (int(bbox[0]), int(bbox[1]))
                p2 = (int(bbox[0]+bbox[2]), int(bbox[1]+bbox[3]))
                cv2.rectangle(frame, p1, p2, (0, 0, 255))
            cv2.imshow('tracking', frame)
            k = cv2.waitKey(1) & 0xff
            if k == 27:
                break

    def test106(self):
        camera = cv2.VideoCapture(1)  # 参数0表示第一个摄像头
        # 判断视频是否打开
        if camera.isOpened():
            print('Open')
        else:
            print('摄像头未打开')

        # 测试用,查看视频size
        size = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)),
                int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))
        print('size:' + repr(size))

        es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 4))
        kernel = np.ones((5, 5), np.uint8)
        background = None

        while True:
            # 读取视频流
            grabbed, frame_lwpCV = camera.read()
            # 对帧进行预处理，先转灰度图，再进行高斯滤波。
            # 用高斯滤波进行模糊处理，进行处理的原因：每个输入的视频都会因自然震动、光照变化或者摄像头本身等原因而产生噪声。对噪声进行平滑是为了避免在运动和跟踪时将其检测出来。
            gray_lwpCV = cv2.cvtColor(frame_lwpCV, cv2.COLOR_BGR2GRAY)
            gray_lwpCV = cv2.GaussianBlur(gray_lwpCV, (21, 21), 0)

            # 将第一帧设置为整个输入的背景
            if background is None:
                background = gray_lwpCV
                continue
            # 对于每个从背景之后读取的帧都会计算其与北京之间的差异，并得到一个差分图（different map）。
            # 还需要应用阈值来得到一幅黑白图像，并通过下面代码来膨胀（dilate）图像，从而对孔（hole）和缺陷（imperfection）进行归一化处理
            diff = cv2.absdiff(background, gray_lwpCV)
            diff = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]  # 二值化阈值处理
            diff = cv2.dilate(diff, es, iterations=2)  # 形态学膨胀

            # 显示矩形框
            image, contours, hierarchy = cv2.findContours(diff.copy(), cv2.RETR_EXTERNAL,
                                                          cv2.CHAIN_APPROX_SIMPLE)  # 该函数计算一幅图像中目标的轮廓
            for c in contours:
                if cv2.contourArea(c) < 1500:  # 对于矩形区域，只显示大于给定阈值的轮廓，所以一些微小的变化不会显示。对于光照不变和噪声低的摄像头可不设定轮廓最小尺寸的阈值
                    continue
                (x, y, w, h) = cv2.boundingRect(c)  # 该函数计算矩形的边界框
                cv2.rectangle(frame_lwpCV, (x, y), (x + w, y + h), (0, 255, 0), 2)

            cv2.imshow('contours', frame_lwpCV)
            cv2.imshow('dis', diff)

            key = cv2.waitKey(1) & 0xFF
            # 按'q'健退出循环
            if key == ord('q'):
                break
        # When everything done, release the capture
        camera.release()
        cv2.destroyAllWindows()

    def test107(self):
        # 捕获视频图像
        camera = cv2.VideoCapture(1)
        # 打开摄像头，将第一帧作为整个输入背景
        es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))
        kernel = np.ones((5, 5), np.uint8)
        background = None

        while (True):
            ret, frame = camera.read()
            # 对背景帧进行灰度和平滑处理
            if background is None:
                background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                background = cv2.GaussianBlur(background, (21, 21), 0)
                continue
                # 将其他帧进行灰度处理和模糊平滑处理
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)
            # 计算其他帧与背景之间的差异，得到一个差分图
            diff = cv2.absdiff(background, gray_frame)
            # 应用阈值得到一副黑白图像，并通过dilate膨胀图像，从而对孔和缺陷进行归一处理
            diff = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]
            diff = cv2.dilate(diff, es, iterations=2)

            # 显示矩形框，在计算出的差分图中找到所有的白色斑点轮廓，并显示轮廓
            image, cnts, hierarchy = cv2.findContours(diff.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for c in cnts:
                if cv2.contourArea(c) < 1500:
                    continue
                (x, y, w, h) = cv2.boundingRect(c)
                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)

            cv2.imshow("contours", frame)
            cv2.imshow("dif", diff)
            if cv2.waitKey(1000 // 12) & 0xff == ord("q"):
                break

        cv2.destroyAllWindows()
        camera.release()

        # KNN in OpenCV
    def test88(self):
        trainData = np.random.randint(0, 100, (25, 2)).astype(np.float32)       # 产生训练数据
        responses = np.random.randint(0, 2, (25, 1)).astype(np.float32)         # 给数据贴标签

        red = trainData[responses.ravel() == 0]                                 # 可视化红色数据
        plt.scatter(red[:, 0], red[:, 1], 80, 'r', '^')

        blue = trainData[responses.ravel() == 1]                                # 可视化蓝色数据
        plt.scatter(blue[:, 0], blue[:, 1], 80, 'b', 's')

        newcomer = np.random.randint(0, 100, (1, 2)).astype(np.float32)         # 产生测试数据
        plt.scatter(newcomer[:, 0], newcomer[:, 1], 80, 'g', 'o')

        knn = cv2.ml.KNearest_create()                                          # OpenCV2.x为：knn = cv2.KNearest()
        knn.train(trainData, cv2.ml.ROW_SAMPLE, responses)                      # 用 kNN 训练数据 OpenCVx.x为：#knn.train(trainData, responses)
        ret, results, neighbours, distance = knn.findNearest(newcomer, 3)           # OpenCV2.x为：ret, results, neighbours, dist = knn.find_nearest(newcommer, 3)

        print('newcomer: ', newcomer)
        print('ret: ', ret)
        print('results: ', results)
        print('neighbours: ', neighbours)
        print('distance: ', distance)
        log(newcomer)
        log(ret)
        log(results)
        log(neighbours)
        log(distance)

        plt.show()

    # 人脸识别
    def test220(self, image):
        """Converts an image to grayscale and prints the locations of any faces found"""
        grayscale = cvCreateImage(cvSize(image.width, image.height), 8, 1)
        cvCvtColor(image, grayscale, CV_BGR2GRAY)

        storage = cvCreateMemStorage(0)
        cvClearMemStorage(storage)
        cvEqualizeHist(grayscale, grayscale)

        cascade = cvLoadHaarClassifierCascade(
            '/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml',
            cvSize(1, 1))
        faces = cvHaarDetectObjects(grayscale, cascade, storage, 1.1, 2,
                                    CV_HAAR_DO_CANNY_PRUNING, cvSize(20, 20))

        result = []
        for f in faces:
            result.append((f.x, f.y, f.x + f.width, f.y + f.height))

        return result

    def test221(self, r, g, b):
        return int(r * .3 + g * .59 + b * .11)

    def test222(self, infile, outfile):
        image = cvLoadImage(infile)
        if image:
            faces = self.test220(image)

        im = Image.open(infile)

        if faces:
            draw = ImageDraw.Draw(im)
            for f in faces:
                draw.rectangle(f, outline=(255, 0, 255))

            im.save(outfile, "JPEG", quality=100)
        else:
            print
            "Error: cannot detect faces on %s" % infile

    # 人脸识别
    def test223(self):
        cv2.namedWindow("test")
        cap = cv2.VideoCapture(0)
        success, frame = cap.read()
        classifier = cv2.CascadeClassifier("haarcascade_frontalface_alt.xml")  # 确保此xml文件与该py文件在一个文件夹下，否则将这里改为绝对路径，此xml文件可在D:\My Documents\Downloads\opencv\sources\data\haarcascades下找到。

        while success:
            success, frame = cap.read()
            size = frame.shape[:2]
            image = np.zeros(size, dtype=np.float16)
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            cv2.equalizeHist(image, image)
            divisor = 8
            h, w = size
            minSize = (w // divisor, h // divisor)
            faceRects = classifier.detectMultiScale(image, 1, 2, cv2.CASCADE_SCALE_IMAGE, minSize)
            if len(faceRects) > 0:
                for faceRect in faceRects:
                    x, y, w, h = faceRect
                    cv2.circle(frame, (x + w / 2, y + h / 2), min(w / 2, h / 2), (255, 0, 0))
                    cv2.circle(frame, (x + w / 4, y + h / 4), min(w / 8, h / 8), (255, 0, 0))
                    cv2.circle(frame, (x + 3 * w / 4, y + h / 4), min(w / 8, h / 8), (255, 0, 0))
                    cv2.rectangle(frame, (x + 3 * w / 8, y + 3 * h / 4), (x + 5 * w / 8, y + 7 * h / 8), (255, 0, 0))
            cv2.imshow("test", frame)
            key = cv2.waitKey(10)
            c = chr(key & 255)
            if c in ['q', 'Q', chr(27)]:
                break
        cv2.destroyWindow("test")

    # KNN in OpenCV
    def test300(self):
        img = cv2.imread(self.__img_digits)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        cells = [np.hsplit(row, 100) for row in np.vsplit(gray, 50)]
        x = np.array(cells)

        train = x[:, :50].reshape(-1, 400).astype(np.float32)
        test = x[:, 50:100].reshape(-1, 400).astype(np.float32)

        k = np.arange(10)
        train_labels = np.repeat(k, 250)[:, np.newaxis]
        test_labels = train_labels.copy()

        knn = cv2.ml.KNearest_create()#knn = cv2.Knearest()
        knn.train(train, cv2.ml.ROW_SAMPLE, train_labels)#knn.train(train, train_labels)
        ret, results, neighbours, dist = knn.findNearest(test, k=5)#ret, results, neighbours, dist = knn.find_nearest(test, k=5)

        matches = results == test_labels
        correct = np.count_nonzero(matches)
        accuracy = correct*100.0/results.size
        print(accuracy)
        np.savez('knn_data.npz', train=train, train_labels=train_labels)

        with np.load('knn_data.npz') as data:
            print(data.files)
            train = data['train']
            train_labels = data['train_labels']


if __name__ == '__main__':
    cv = OpenCVExercise()
    #cv.test20()
    cv.test21(r"C:\Users\caoyanjie\Desktop\微信图片_20180417193744.jpg")
